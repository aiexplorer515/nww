"""
NWW Streamlit Dashboard - Complete Automation Package UI
"""

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import json, os, logging
from datetime import datetime

# Import NWW modules
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Import the actual modules that exist
try:
    from ingest import Extractor
    from preprocess import Normalizer
    from analyze import Tagger
    from rules import Gating
    from score import ScoreIS, ScoreDBN, LLMJudge
    from fusion import FusionCalibration
    from eds import EDSBlockMatcher
    from scenario import ScenarioBuilder
    from decider import AlertDecider
    from ledger import AuditLedger
    from eventblock import EventBlockAggregator
except ImportError as e:
    st.error(f"Import error: {e}")
    st.stop()

# -------------------------------------------------------------------
# Logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# -------------------------------------------------------------------
# Pipeline Runner
def run_pipeline(urls, out_dir="data/bundles/sample"):
    """Run the complete NWW pipeline."""
    os.makedirs(out_dir, exist_ok=True)
    os.makedirs(os.path.join(out_dir, "logs"), exist_ok=True)

    try:
    # 1) Ingest
        st.info("ğŸ”„ Step 1: Data Ingestion...")
        extractor = Extractor(out_dir)
        articles_path = os.path.join(out_dir, "articles.jsonl")
        extractor.run(articles_path)
        
        # Load articles for demo
        articles = []
        if os.path.exists(articles_path):
            with open(articles_path, 'r', encoding='utf-8') as f:
                for line in f:
                    try:
                        articles.append(json.loads(line.strip()))
                    except:
                        continue

    # 2) Normalize
        st.info("ğŸ”„ Step 2: Text Normalization...")
        normalizer = Normalizer()
        norm_path = os.path.join(out_dir, "articles.norm.jsonl")
        log_path = os.path.join(out_dir, "logs", "normalize.log")
        normalizer.run(articles_path, norm_path, log_path)

        # 3) Analyze
        st.info("ğŸ”„ Step 3: Text Analysis...")
        tagger = Tagger()
        analysis_path = os.path.join(out_dir, "kyw_sum.jsonl")
        tagger.run(norm_path, analysis_path)

    # 4) Gating
        st.info("ğŸ”„ Step 4: Content Gating...")
        gating = Gating()
        gated_path = os.path.join(out_dir, "gated.jsonl")
        gating.run(analysis_path, gated_path)

    # 5) Scoring
        st.info("ğŸ”„ Step 5: Multi-modal Scoring...")
        scores_path = os.path.join(out_dir, "scores.jsonl")
        
        # IS Scoring
        score_is = ScoreIS()
        score_is.run(gated_path, scores_path)
        
        # DBN Scoring
        score_dbn = ScoreDBN()
        score_dbn.run(out_dir, scores_path)
        
        # LLM Scoring
        score_llm = LLMJudge()
        score_llm.run(out_dir, scores_path)

        # 6) Fusion
        st.info("ğŸ”„ Step 6: Score Fusion...")
        fusion = FusionCalibration()
        fused_path = os.path.join(out_dir, "fused_scores.jsonl")
        fusion.run(scores_path, fused_path)

        # 7) Blocks
        st.info("ğŸ”„ Step 7: EDS Block Matching...")
        block_matcher = EDSBlockMatcher()
        blocks_path = os.path.join(out_dir, "blocks.jsonl")
        block_matcher.run(out_dir, blocks_path)

        # 8) Scenarios
        st.info("ğŸ”„ Step 8: Scenario Construction...")
        scenario_builder = ScenarioBuilder()
        scenarios_path = os.path.join(out_dir, "scenarios.jsonl")
        scenario_builder.run(out_dir, scenarios_path)

        # 9) Alerts
        st.info("ğŸ”„ Step 9: Alert Generation...")
        alert_decider = AlertDecider()
        alerts_path = os.path.join(out_dir, "alerts.jsonl")
        alert_decider.run(out_dir, alerts_path)

        # 10) Ledger
        st.info("ğŸ”„ Step 10: Audit Trail...")
        audit_ledger = AuditLedger()
        ledger_path = os.path.join(out_dir, "ledger.jsonl")
        audit_ledger.run(out_dir, ledger_path)

        # Load results for demo
        alerts = []
        if os.path.exists(alerts_path):
            with open(alerts_path, 'r', encoding='utf-8') as f:
                for line in f:
                    try:
                        alerts.append(json.loads(line.strip()))
                    except:
                        continue

    return {
        "articles": articles,
            "scores": [],  # Placeholder
            "blocks": [],  # Placeholder
            "scenarios": [],  # Placeholder
        "alerts": alerts
    }

    except Exception as e:
        st.error(f"âŒ Pipeline error: {e}")
        return {
            "articles": [],
            "scores": [],
            "blocks": [],
            "scenarios": [],
            "alerts": []
        }

# -------------------------------------------------------------------
# Main UI
def main():
    st.set_page_config(
        page_title="ğŸŒ NWW Dashboard",
        page_icon="ğŸŒ",
        layout="wide",
        initial_sidebar_state="expanded"
    )

    if 'bundle_dir' not in st.session_state:
        st.session_state.bundle_dir = "data/bundles/sample"
    if 'processing_status' not in st.session_state:
        st.session_state.processing_status = {}

    # ì‚¬ì´ë“œë°”
    render_sidebar()

    st.title("ğŸŒ NWW - News War Watch")
    st.markdown("**ìœ„ê¸° ì¡°ê¸° íƒì§€ ë° ë¶„ì„ ìë™í™” íŒ¨í‚¤ì§€**")

    # Tabs
    landing, overview, ingest_tab, scoring_tab, timeline_tab, blocks_tab, scenarios_tab, artifacts_tab, ledger_tab = st.tabs([
        "ğŸ¦‰ ëœë”©", "ğŸ“Š Overview", "ğŸ“¥ Ingest", "ğŸ¯ Scoring",
        "â° Timeline", "ğŸ§± Blocks", "ğŸ“‹ Scenarios", "ğŸ“¦ Artifacts", "ğŸ“ Ledger"
    ])

    with landing:
        render_landing_tab()
    with overview:
        render_overview_tab()
    with ingest_tab:
        render_ingest_tab()
    with scoring_tab:
        render_scoring_tab()
    with timeline_tab:
        render_timeline_tab()
    with blocks_tab:
        render_blocks_tab()
    with scenarios_tab:
        render_scenarios_tab()
    with artifacts_tab:
        render_artifacts_tab()
    with ledger_tab:
        render_ledger_tab()

# -------------------------------------------------------------------
# Sidebar
def render_sidebar():
    st.sidebar.title("âš™ï¸ Configuration")

    st.sidebar.text_input("Bundle Directory", value=st.session_state.bundle_dir)

    st.sidebar.subheader("ğŸ”§ Settings")
    st.sidebar.slider("Alert Threshold", 0.0, 1.0, 0.7, 0.05)
    st.sidebar.slider("EMA Alpha", 0.0, 1.0, 0.3, 0.05)
    st.sidebar.slider("Hysteresis", 0.0, 0.5, 0.1, 0.01)

    st.sidebar.markdown("---")
    if st.sidebar.button("ğŸš€ Run All Modules", type="primary"):
        st.success("ğŸ‰ Demo: All modules executed")

    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ“ˆ Status")
    modules = ["Ingest", "Normalize", "Analyze", "Gate", "Score IS", "Score DBN", "Score LLM", "Fusion", "Blocks", "Scenarios", "Alerts", "Ledger"]
    for m in modules:
        st.sidebar.info(f"â¸ï¸ {m}")

# -------------------------------------------------------------------
# ëœë”© íƒ­
def render_landing_tab():
    st.header("ğŸ¦‰ Crisis Overview")
    
    # Try to get alerts from session state first, then from file
    alerts = None
    if hasattr(st.session_state, 'alerts') and st.session_state.alerts:
        alerts = pd.DataFrame(st.session_state.alerts)
    else:
        alerts = get_alerts()
    
    if alerts is not None and not alerts.empty:
        col1, col2 = st.columns(2)
        with col1:
            st.subheader("ğŸŒ ì§€ì—­ë³„ ìœ„ê¸° í˜„í™©")
            if "region" in alerts.columns:
                region_stats = alerts.groupby("region")["score"].count().reset_index(name="Active Alerts")
                fig1 = px.bar(region_stats, x="region", y="Active Alerts", color="region", title="ì§€ì—­ë³„ ìœ„ê¸° í˜„í™©")
                st.plotly_chart(fig1, use_container_width=True)
            else:
                st.warning("âš ï¸ ë°ì´í„°ì— 'region' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        with col2:
            st.subheader("âš”ï¸ ë¶„ì•¼ë³„ ìœ„ê¸° í˜„í™©")
            if "domain" in alerts.columns:
                domain_stats = alerts.groupby("domain")["score"].count().reset_index(name="Count")
                fig2 = px.pie(domain_stats, values="Count", names="domain", title="ë¶„ì•¼ë³„ ìœ„ê¸° í˜„í™©")
                st.plotly_chart(fig2, use_container_width=True)
            else:
                st.warning("âš ï¸ ë°ì´í„°ì— 'domain' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("ğŸ“ ì•„ì§ í™œì„± ì•Œë¦¼ì´ ì—†ìŠµë‹ˆë‹¤. Ingest íƒ­ì—ì„œ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
        
        # Show sample data for demonstration
        st.subheader("ğŸ“Š Sample Dashboard Preview")
        
        # Sample region data
        st.subheader("ğŸŒ Crisis by Region (Sample)")
        sample_regions = pd.DataFrame({
            'region': ['asia', 'europe', 'americas', 'middle_east', 'africa'],
            'count': [45, 32, 28, 15, 8]
        })
        fig = px.bar(sample_regions, x='region', y='count', 
                    title="Sample Regional Crisis Distribution",
                    color='count', color_continuous_scale="Reds")
        st.plotly_chart(fig, use_container_width=True)
        
        # Sample domain data
        st.subheader("ğŸ“‚ Crisis by Domain (Sample)")
        sample_domains = pd.DataFrame({
            'domain': ['military', 'diplomacy', 'economy'],
            'count': [35, 28, 22]
        })
        fig = px.pie(sample_domains, names='domain', values='count',
                    title="Sample Domain Distribution")
        st.plotly_chart(fig, use_container_width=True)

# -------------------------------------------------------------------
# Placeholders for other tabs
def render_overview_tab():
    st.header("ğŸ“Š Overview")
    st.success("ìƒ˜í”Œ: Overview ì •ìƒ ë™ì‘")

def render_ingest_tab():
    st.header("ğŸ“¥ Data Ingestion & Pipeline")

    # URL input
    urls = st.text_area("Enter URLs (one per line):", height=150, 
                       placeholder="https://www.reuters.com/world/\nhttps://www.bbc.com/news\nhttps://www.cnn.com/world")

    # Sample URLs button
    if st.button("ğŸ“‹ Load Sample URLs"):
        sample_urls = """https://www.reuters.com/world/
https://www.bbc.com/news
https://www.cnn.com/world
https://www.ap.org/news"""
        st.session_state.sample_urls = sample_urls
        st.rerun()

    if "sample_urls" in st.session_state:
        st.text_area("Sample URLs loaded:", value=st.session_state.sample_urls, height=100, disabled=True)

    # Pipeline execution
    if st.button("ğŸš€ Run Full Pipeline", type="primary"):
        if not urls.strip():
            st.warning("â— URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            url_list = [u.strip() for u in urls.splitlines() if u.strip()]
            
            # Create progress bar
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            try:
                status_text.text("ğŸ”„ Starting pipeline...")
                progress_bar.progress(10)
                
                results = run_pipeline(url_list, out_dir=st.session_state.bundle_dir)
                
                progress_bar.progress(100)
                status_text.text("âœ… Pipeline completed!")
                
            st.session_state.articles = results["articles"]
            st.session_state.alerts = results["alerts"]
            st.success("âœ… ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ!")

            except Exception as e:
                st.error(f"âŒ Pipeline failed: {e}")
                progress_bar.progress(0)
                status_text.text("âŒ Pipeline failed")

    # Display results
    if hasattr(st.session_state, 'articles') and st.session_state.articles:
        st.subheader("ğŸ“Š Processed Articles")
        df = pd.DataFrame(st.session_state.articles)
        
        # Show available columns
        available_cols = ["id", "title", "ts"]
        if "region" in df.columns:
            available_cols.append("region")
        if "domain" in df.columns:
            available_cols.append("domain")
        if "lang" in df.columns:
            available_cols.append("lang")
            
        st.dataframe(df[available_cols], use_container_width=True)
        
        # Show statistics
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Total Articles", len(df))
        with col2:
            if "region" in df.columns:
                st.metric("Regions", df["region"].nunique())
        with col3:
            if "domain" in df.columns:
                st.metric("Domains", df["domain"].nunique())
    else:
        st.info("ğŸ“ No articles processed yet. Enter URLs and run the pipeline.")

def render_scoring_tab():
    st.header("ğŸ¯ Scoring")
    st.info("ìƒ˜í”Œ: ì ìˆ˜ ë¶„ì„ íƒ­ (êµ¬í˜„ í•„ìš”)")

def render_timeline_tab():
    st.header("â° Timeline")
    st.info("ìƒ˜í”Œ: ì‹œê³„ì—´ ë¶„ì„ íƒ­ (êµ¬í˜„ í•„ìš”)")

def render_blocks_tab():
    st.header("ğŸ§± Blocks")
    st.info("ìƒ˜í”Œ: EDS ë¸”ë¡ íƒ­ (êµ¬í˜„ í•„ìš”)")

def render_scenarios_tab():
    st.header("ğŸ“‹ Scenarios")
    st.info("ìƒ˜í”Œ: ì‹œë‚˜ë¦¬ì˜¤ íƒ­ (êµ¬í˜„ í•„ìš”)")

def render_artifacts_tab():
    st.header("ğŸ“¦ Artifacts")
    st.info("ìƒ˜í”Œ: ë‚´ë³´ë‚´ê¸° íƒ­ (êµ¬í˜„ í•„ìš”)")

def render_ledger_tab():
    st.header("ğŸ“ Ledger")
    st.info("ìƒ˜í”Œ: ê°ì‚¬ ë¡œê·¸ íƒ­ (êµ¬í˜„ í•„ìš”)")

# -------------------------------------------------------------------
# Helpers
def get_alerts():
    try:
        alerts_path = os.path.join(st.session_state.bundle_dir, "alerts.jsonl")
        if os.path.exists(alerts_path):
            data = []
            with open(alerts_path, "r", encoding="utf-8") as f:
                for line in f:
                    try:
                        data.append(json.loads(line.strip()))
                    except:
                        continue
            if data:
                return pd.DataFrame(data)
    except Exception as e:
        logger.error(f"Error loading alerts.jsonl: {e}")
    return None

# -------------------------------------------------------------------
if __name__ == "__main__":
    main()
