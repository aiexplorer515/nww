import os, json, re, io, math, random
from datetime import datetime, timedelta

import pandas as pd
import numpy as np
import streamlit as st
import plotly.express as px
import matplotlib.pyplot as plt
from wordcloud import WordCloud

# =========================
# ì•ˆì „ IO (í†µí•©)
# =========================
def load_jsonl(path: str) -> pd.DataFrame:
    if not os.path.exists(path):
        return pd.DataFrame()
    with open(path, "r", encoding="utf-8") as f:
        lines = []
        for line in f:
            try:
                lines.append(json.loads(line))
            except Exception:
                continue
    return pd.DataFrame(lines)

def save_jsonl(df: pd.DataFrame, path: str):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        for _, row in df.iterrows():
            rec = row.to_dict()
            for k, v in rec.items():
                if isinstance(v, pd.Timestamp):
                    rec[k] = v.isoformat()
                elif isinstance(v, float) and pd.isna(v):
                    rec[k] = None
                elif isinstance(v, (pd.Series, pd.DataFrame)):
                    rec[k] = str(v)
            f.write(json.dumps(rec, ensure_ascii=False) + "\n")

# =========================
# í…ìŠ¤íŠ¸ ìœ í‹¸
# =========================
def normalize_text(text: str) -> str:
    if not isinstance(text, str):
        return ""
    text = text.replace("\u200b", " ")
    text = re.sub(r"\s+", " ", text.strip())
    text = text.lower()
    # ì˜/ìˆ«/í•œ/ê³µë°±ë§Œ ë‚¨ê¹€
    return re.sub(r"[^a-z0-9ê°€-í£\s]", " ", text).strip()

def sent_split(text: str) -> list[str]:
    if not isinstance(text, str) or not text.strip():
        return []
    # ê°„ë‹¨ ë¶„ë¦¬(.!?/ê°œí–‰)
    parts = re.split(r"[\.!\?\n]+", text)
    return [p.strip() for p in parts if p.strip()]

def tok(text: str) -> list[str]:
    return [t for t in text.split() if t]

# =========================
# ê°„ì´ ê°ì •/í”„ë ˆì„/ë„ë©”ì¸ ë£°
# =========================
POS_WORDS = set("ì§„ì „ ì™„í™” íšŒë³µ í•©ì˜ ê°œì„  ë°˜ë“± ìƒìŠ¹ ì•ˆì • í‰í™” í˜‘ë ¥ ì§€ì› êµ¬ì¡° ì„±ê³µ í™•ì¥ ë„ì•½".split())
NEG_WORDS = set("ìœ„ê¸° ì „ìŸ ì¶©ëŒ êµì „ ì‚¬ë§ ë¶€ìƒ íŒŒì—… ë¶•ê´´ ì¹¨ì²´ í­ë½ ì••ë°• ì œì¬ ê¸´ì¥ ë¹„ìƒ ê²½ê³  íŒŒíƒ„".split())

FRAME_LEXICON = {
    "Conflict":  ["ì¶©ëŒ","ì „ìŸ","êµì „","êµ°ì‚¬","ë¯¸ì‚¬ì¼","ê³µìŠµ","ì‚¬ë§","ë¶€ìƒ","ë°œí¬","ë³‘ë ¥","í›ˆë ¨","í•µ","í¬ê²©","êµì „"],
    "Diplomacy": ["í˜‘ìƒ","íšŒë‹´","í•©ì˜","ì¤‘ì¬","ì™¸êµ","ì œì¬ì™„í™”","ì •ìƒíšŒë‹´","í†µí™”","ì„œí•œ","ì ‘ì´‰"],
    "Economic":  ["ë¬¼ê°€","ê¸ˆë¦¬","í™˜ìœ¨","ì£¼ê°€","ì„±ì¥","ì‹¤ì—…","ìœ„ê¸°","ì œì¡°ì—…","ìˆ˜ì¶œ","ê³µê¸‰ë§","ì¬ì •","ë¶€ì±„","ì ì","íˆ¬ì","íŒŒì—…","ì„ê¸ˆ"],
    "Domestic":  ["ì´ì„ ","ëŒ€ì„ ","ì˜íšŒ","ë²•ì•ˆ","ì‹œìœ„","ê²€ì°°","ëŒ€ë²•ì›","ë‚´ê°","ì–¸ë¡ ","ë¶€íŒ¨","íƒ„í•µ"],
    "Disaster":  ["ì§€ì§„","íƒœí’","í­ìš°","í™ìˆ˜","ê°€ë­„","í™”ì¬","ì‚°ë¶ˆ","ì°¸ì‚¬","ì „ì—¼ë³‘","í™•ì§„","ê²©ë¦¬","í”¼í•´"]
}

DOMAIN_FROM_FRAME = {
    "Conflict": "Security",
    "Diplomacy": "Political",
    "Economic": "Economic",
    "Domestic": "Political",
    "Disaster": "Disaster"
}

REGION_REGEX = {
    "Korea": r"(í•œêµ­|ëŒ€í•œë¯¼êµ­|ì„œìš¸|ë¶€ì‚°|ì¸ì²œ|ëŒ€êµ¬|ëŒ€ì „|ê´‘ì£¼)",
    "US": r"(ë¯¸êµ­|ì›Œì‹±í„´|ë‰´ìš•|LA|ìº˜ë¦¬í¬ë‹ˆì•„|ë°”ì´ë“ |íœíƒ€ê³¤)",
    "China": r"(ì¤‘êµ­|ë² ì´ì§•|ìƒí•˜ì´|ì‹œì§„í•‘)",
    "Japan": r"(ì¼ë³¸|ë„ì¿„|ì˜¤ì‚¬ì¹´|ê¸°ì‹œë‹¤)",
    "Russia": r"(ëŸ¬ì‹œì•„|ëª¨ìŠ¤í¬ë°”|í‘¸í‹´)",
    "EU": r"(ìœ ëŸ½ì—°í•©|EU|ë¸Œë¤¼ì…€|ë…ì¼|í”„ë‘ìŠ¤|ì´íƒˆë¦¬ì•„|ìŠ¤í˜ì¸)",
}

def infer_region(text: str) -> str:
    for r, pat in REGION_REGEX.items():
        if re.search(pat, text or "", flags=re.IGNORECASE):
            return r
    return "Unknown"

def infer_sentiment(tokens: list[str]) -> float:
    if not tokens:
        return 0.0
    pos = sum(1 for t in tokens if t in POS_WORDS)
    neg = sum(1 for t in tokens if t in NEG_WORDS)
    # [-1, 1] ë²”ìœ„
    if pos == 0 and neg == 0:
        return 0.0
    score = (pos - neg) / max(1, (pos + neg))
    return float(max(-1, min(1, score)))

def infer_frame(tokens: list[str]) -> tuple[str, dict]:
    hits = {}
    for frame, kws in FRAME_LEXICON.items():
        hits[frame] = sum(1 for t in tokens for k in kws if k in t)
    best = max(hits, key=hits.get) if hits else "Unknown"
    return best if hits[best] > 0 else "Unknown", hits

# =========================
# TF-IDF (ê°„ì´ êµ¬í˜„)
# =========================
def tfidf_topk(docs: list[list[str]], topk: int = 10) -> list[list[tuple[str,float]]]:
    if not docs:
        return [[]]
    # DF
    df_counter = {}
    for tokens in docs:
        for w in set(tokens):
            df_counter[w] = df_counter.get(w, 0) + 1
    n_docs = len(docs)
    out = []
    for tokens in docs:
        tf = {}
        for w in tokens:
            tf[w] = tf.get(w, 0) + 1
        scores = []
        for w, c in tf.items():
            idf = math.log((n_docs + 1) / (1 + df_counter.get(w, 1))) + 1
            scores.append((w, (c / len(tokens)) * idf))
        scores.sort(key=lambda x: x[1], reverse=True)
        out.append(scores[:topk])
    return out

# =========================
# ê³µí†µ ê²½ë¡œ
# =========================
def P(bundle: str, name: str) -> str:
    return os.path.join("data", bundle, name)

# =========================
# Landing
# =========================
def page_overview(bundle: str):
    import plotly.express as px
    import pandas as pd
    import streamlit as st
    from datetime import date, timedelta

    st.title("ğŸŒ NWW Crisis Overview")

    # ë°ì´í„° ë¡œë“œ
    df_alerts = load_jsonl(P(bundle, "alerts.jsonl"))
    df_scen   = load_jsonl(P(bundle, "scenarios.jsonl"))
    df_an     = load_jsonl(P(bundle, "analyze.jsonl"))  # í”„ë ˆì„ í†µê³„ìš©

    # =========================
    # KPI (ê¸°ì‚¬ ìˆ˜ / í™œì„± ì•Œë¦¼ ìˆ˜ / í‰ê·  ìœ„í—˜ë„)
    # =========================
    total_articles = len(df_alerts) if not df_alerts.empty else 0

    # í™œì„± ì•Œë¦¼ ìˆ˜: is_alert ë˜ëŠ” alert ì»¬ëŸ¼ ìš°ì„  ì‚¬ìš©
    if not df_alerts.empty and "is_alert" in df_alerts.columns:
        active_alerts = int(pd.to_numeric(df_alerts["is_alert"], errors="coerce").fillna(0).sum())
    elif not df_alerts.empty and "alert" in df_alerts.columns:
        active_alerts = int(pd.to_numeric(df_alerts["alert"], errors="coerce").fillna(0).sum())
    else:
        active_alerts = 0

    # í‰ê·  ìœ„í—˜ë„: risk > risk_fused > score ìˆœìœ¼ë¡œ íƒìƒ‰
    if not df_alerts.empty:
        if "risk" in df_alerts.columns:
            avg_series = pd.to_numeric(df_alerts["risk"], errors="coerce").fillna(0)
        elif "risk_fused" in df_alerts.columns:
            avg_series = pd.to_numeric(df_alerts["risk_fused"], errors="coerce").fillna(0)
        elif "score" in df_alerts.columns:
            avg_series = pd.to_numeric(df_alerts["score"], errors="coerce").fillna(0)
        else:
            avg_series = pd.Series([], dtype="float64")
        avg_score = float(avg_series.mean()) if not avg_series.empty else 0.0
    else:
        avg_score = 0.0

    c1, c2, c3 = st.columns(3)
    c1.metric("ê¸°ì‚¬ ìˆ˜", total_articles)
    c2.metric("í™œì„± ì•Œë¦¼ ìˆ˜", active_alerts)
    c3.metric("í‰ê·  ìœ„í—˜ë„", f"{avg_score:.2f}")

    st.markdown("---")

    # =========================
    # ìµœê·¼ 7ì¼ ì•Œë¦¼ ì¶”ì„¸ (line chart)
    # =========================
    st.subheader("ğŸ“ˆ ìµœê·¼ 7ì¼ ì•Œë¦¼ ì¶”ì„¸")
    if not df_alerts.empty and "date" in df_alerts.columns:
        dcol = pd.to_datetime(df_alerts["date"], errors="coerce").dt.date
        tmp = df_alerts.copy()
        tmp["__date"] = dcol

        # is_alertê°€ ìˆìœ¼ë©´ ì•Œë¦¼ë§Œ ì§‘ê³„, ì—†ìœ¼ë©´ ì „ì²´ ê¸°ì‚¬ ìˆ˜ ì§‘ê³„
        if "is_alert" in tmp.columns:
            tmp["__alerts"] = pd.to_numeric(tmp["is_alert"], errors="coerce").fillna(0)
        elif "alert" in tmp.columns:
            tmp["__alerts"] = pd.to_numeric(tmp["alert"], errors="coerce").fillna(0)
        else:
            tmp["__alerts"] = 1  # ëŒ€ì²´: ì•Œë¦¼ ì»¬ëŸ¼ ì—†ìœ¼ë©´ ì „ì²´ ê±´ìˆ˜

        daily = tmp.dropna(subset=["__date"]).groupby("__date")["__alerts"].sum().reset_index()
        daily.columns = ["date", "alerts"]

        # ìµœê·¼ 7ì¼ë§Œ ë³´ì´ë„ë¡ ë³´ì •(ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ì±„ì›€)
        if not daily.empty:
            end = date.today()
            idx = pd.date_range(end=end, periods=7, freq="D").date
            grid = pd.DataFrame({"date": idx})
            daily = grid.merge(daily, on="date", how="left").fillna({"alerts": 0})
            fig = px.line(daily, x="date", y="alerts", markers=True, title="ìµœê·¼ 7ì¼ ì•Œë¦¼ ë°œìƒ ì¶”ì„¸")
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("í‘œì‹œí•  ì¼ì ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("ì•Œë¦¼ ì‹œê³„ì—´ì„ í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("---")

    # =========================
    # Top 5 ìœ„í—˜ ì‹œë‚˜ë¦¬ì˜¤ (í…Œì´ë¸”/ì¹´ë“œ)
    # =========================
    st.subheader("ğŸ”¥ Top 5 ìœ„í—˜ ì‹œë‚˜ë¦¬ì˜¤")
    if not df_scen.empty:
        # ìœ„í—˜ë„ ê¸°ì¤€ ì»¬ëŸ¼ ì„ íƒ
        if "risk" in df_scen.columns:
            key = "risk"
        elif "score" in df_scen.columns:
            key = "score"
        elif "risk_fused" in df_scen.columns:
            key = "risk_fused"
        else:
            key = None

        if key:
            tmp = df_scen.copy()
            tmp[key] = pd.to_numeric(tmp[key], errors="coerce").fillna(0)
            top5 = tmp.sort_values(key, ascending=False).head(5)

            # ë³´ê¸° ì¢‹ì€ ì»¬ëŸ¼ ìš°ì„  ì„ íƒ
            cols = [c for c in ["title","scenario","frame","domain",key] if c in top5.columns]
            if not cols:
                cols = [key]
            st.dataframe(top5[cols], use_container_width=True)
        else:
            st.info("ì‹œë‚˜ë¦¬ì˜¤ ìœ„í—˜ë„ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("ì‹œë‚˜ë¦¬ì˜¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("---")

    # =========================
    # ì§€ì—­ë³„ ë¶„í¬ (bar) / ë¶„ì•¼ë³„ ë¶„í¬ (pie)
    # =========================
    st.subheader("ğŸŒ ì§€ì—­/ë¶„ì•¼ ë¶„í¬")
    # ì§€ì—­ ë°ì´í„° ì†ŒìŠ¤ ìš°ì„ ìˆœìœ„: alerts â†’ analyze â†’ scenarios
    region_src = None
    if not df_alerts.empty and "region" in df_alerts.columns:
        region_src = df_alerts["region"]
    elif not df_an.empty and "region" in df_an.columns:
        region_src = df_an["region"]
    elif not df_scen.empty and "region" in df_scen.columns:
        region_src = df_scen["region"]

    if region_src is not None:
        rc = region_src.fillna("Unknown").value_counts().reset_index()
        rc.columns = ["region", "count"]
        fig_region = px.bar(rc, x="region", y="count", text="count", title="ì§€ì—­ë³„ ë¶„í¬")
        fig_region.update_traces(textposition="outside")
        st.plotly_chart(fig_region, use_container_width=True)
    else:
        st.info("ì§€ì—­ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # ë„ë©”ì¸ ë°ì´í„° ì†ŒìŠ¤ ìš°ì„ ìˆœìœ„: alerts â†’ analyze â†’ scenarios
    domain_src = None
    if not df_alerts.empty and "domain" in df_alerts.columns:
        domain_src = df_alerts["domain"]
    elif not df_an.empty and "domain" in df_an.columns:
        domain_src = df_an["domain"]
    elif not df_scen.empty and "domain" in df_scen.columns:
        domain_src = df_scen["domain"]

    if domain_src is not None:
        dom = pd.DataFrame({"domain": domain_src.fillna("Unknown")})
        fig_dom = px.pie(dom, names="domain", title="ë¶„ì•¼ë³„ ë¶„í¬")
        st.plotly_chart(fig_dom, use_container_width=True)
    else:
        st.info("ë¶„ì•¼ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("---")

    # =========================
    # í”„ë ˆì„ ë¶„í¬ (bar) â€“ ì˜µì…˜(ìˆì„ ë•Œë§Œ)
    # =========================
    st.subheader("ğŸ§© í”„ë ˆì„ ë¶„í¬")
    frame_src = None
    if not df_alerts.empty and "frame" in df_alerts.columns:
        frame_src = df_alerts["frame"]
    elif not df_an.empty and "frame" in df_an.columns:
        frame_src = df_an["frame"]

    if frame_src is not None:
        fr = frame_src.fillna("Unknown").value_counts().reset_index()
        fr.columns = ["frame", "count"]
        fig_fr = px.bar(fr, x="frame", y="count", text="count", title="í”„ë ˆì„ ë¶„í¬")
        fig_fr.update_traces(textposition="outside")
        st.plotly_chart(fig_fr, use_container_width=True)
    else:
        st.info("í”„ë ˆì„ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")

# =========================
# Ingest (URL/ì›ë¬¸)
# =========================
def try_fetch(url: str) -> str | None:
    """trafilatura/bs4ê°€ ìˆìœ¼ë©´ í™œìš©, ì—†ìœ¼ë©´ í´ë°±"""
    if not url:
        return None
    # trafilatura
    try:
        import trafilatura
        downloaded = trafilatura.fetch_url(url, timeout=8)
        if downloaded:
            text = trafilatura.extract(downloaded)
            if text and len(text) > 80:
                return text
    except Exception:
        pass
    # requests + bs4
    try:
        import requests
        from bs4 import BeautifulSoup
        r = requests.get(url, timeout=8, headers={"User-Agent":"Mozilla/5.0"})
        if r.ok:
            soup = BeautifulSoup(r.text, "html.parser")
            ps = [p.get_text(" ", strip=True) for p in soup.find_all("p")]
            text = " ".join(ps)
            return text if len(text) > 80 else None
    except Exception:
        pass
    return None

def page_ingest(bundle: str):
    st.header("ğŸ“° Ingest â€“ ê¸°ì‚¬ ìˆ˜ì§‘")
    url  = st.text_input("ê¸°ì‚¬ URL (ì„ íƒ)")
    text = st.text_area("ê¸°ì‚¬ ì›ë¬¸ (ì„ íƒ)", height=200, placeholder="URLì´ ì•ˆ ë  ë•Œ ì›ë¬¸ì„ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.")

    colA, colB = st.columns([1,1])
    with colA:
        if st.button("ğŸ’¾ ê¸°ì‚¬ ì €ì¥"):
            if not (url or text):
                st.warning("URL ë˜ëŠ” ì›ë¬¸ ì¤‘ í•˜ë‚˜ëŠ” ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.")
            else:
                fetched = text
                if not fetched and url:
                    with st.spinner("URLì—ì„œ ë³¸ë¬¸ ì¶”ì¶œ ì¤‘..."):
                        fetched = try_fetch(url)
                df = load_jsonl(P(bundle, "ingest.jsonl"))
                new = {
                    "id": int(datetime.utcnow().timestamp()*1000) + random.randint(0, 999),
                    "url": url or None,
                    "text": fetched or "",
                    "date": datetime.utcnow().date().isoformat(),
                    "source": "URL" if url and fetched else ("Manual" if text else "URL(no-body)")
                }
                df = pd.concat([df, pd.DataFrame([new])], ignore_index=True)
                save_jsonl(df, P(bundle, "ingest.jsonl"))
                st.success("âœ… ì €ì¥ ì™„ë£Œ")
    with colB:
        if st.button("ğŸ§¹ ì „ì²´ ì‚­ì œ(ingest.jsonl)"):
            p = P(bundle, "ingest.jsonl")
            if os.path.exists(p):
                os.remove(p)
                st.warning("ì‚­ì œ ì™„ë£Œ")

    st.markdown("### ğŸ“„ ì €ì¥ëœ ê¸°ì‚¬")
    df = load_jsonl(P(bundle, "ingest.jsonl"))
    if df.empty:
        st.info("ì €ì¥ëœ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    st.dataframe(df[["date","url","source"]].tail(50), use_container_width=True)

    st.markdown("### ğŸ· ì–¸ë¡ ì‚¬(ì†ŒìŠ¤) ë¶„í¬")
    counts = df["source"].fillna("Unknown").value_counts().reset_index()
    counts.columns = ["source","count"]
    fig = px.bar(counts, x="source", y="count", text="count", title="ì–¸ë¡ ì‚¬ë³„ ê¸°ì‚¬ ë¶„í¬")
    fig.update_traces(textposition="outside")
    st.plotly_chart(fig, use_container_width=True)

# =========================
# Normalize
# =========================
def page_normalize(bundle: str):
    st.header("ğŸ”¤ Normalize â€“ í…ìŠ¤íŠ¸ ì •ê·œí™”")
    df = load_jsonl(P(bundle, "ingest.jsonl"))
    if df.empty:
        st.info("ë¨¼ì € Ingestì—ì„œ ê¸°ì‚¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        return

    df["norm"]   = df["text"].apply(normalize_text)
    df["sents"]  = df["norm"].apply(sent_split)
    df["tokens"] = df["norm"].apply(tok)
    df["tok_len"]= df["tokens"].apply(len)

    st.subheader("ì›ë¬¸ â†” ì •ê·œí™” ë¹„êµ (ìƒ˜í”Œ)")
    st.dataframe(df[["text","norm"]].head(10), use_container_width=True)

    st.subheader("ë¬¸ì¥ ê¸¸ì´(í† í° ìˆ˜) ë¶„í¬")
    st.plotly_chart(px.histogram(df, x="tok_len", nbins=20), use_container_width=True)

    save_jsonl(df, P(bundle, "normalize.jsonl"))
    st.success("normalize.jsonl ì €ì¥ ì™„ë£Œ")

    # ë‹¤ìš´ë¡œë“œ
    buf = io.StringIO(); df.to_csv(buf, index=False, encoding="utf-8-sig")
    st.download_button("â¬‡ï¸ CSV ë‹¤ìš´ë¡œë“œ", buf.getvalue(), file_name=f"{bundle}_normalized.csv", mime="text/csv")

# =========================
# Analyze (TF-IDF/ê°ì •/í”„ë ˆì„/ì§€ì—­/ë„ë©”ì¸)
# =========================
def page_analyze(bundle: str):
    st.header("ğŸ” Analyze â€“ í‚¤ì›Œë“œÂ·ê°ì •Â·í”„ë ˆì„")
    df = load_jsonl(P(bundle, "normalize.jsonl"))
    if df.empty:
        st.info("Normalize ê²°ê³¼ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        return

    # TF-IDF ìƒìœ„ í‚¤ì›Œë“œ
    docs = df["tokens"].apply(lambda x: x if isinstance(x, list) else []).tolist()
    topk = tfidf_topk(docs, topk=10)
    df["keywords"] = [kws for kws in topk]

    # ê°ì •/í”„ë ˆì„/ì§€ì—­/ë„ë©”ì¸
    df["sentiment"] = df["tokens"].apply(infer_sentiment)
    fr_dom = df["tokens"].apply(infer_frame)
    df["frame"]  = [fd[0] for fd in fr_dom]
    df["frame_hits"] = [fd[1] for fd in fr_dom]
    df["domain"] = df["frame"].apply(lambda f: DOMAIN_FROM_FRAME.get(f, "Other"))
    df["region"] = df["norm"].apply(infer_region)

    st.subheader("í‚¤ì›Œë“œ/í”„ë ˆì„/ê°ì • (ìƒ˜í”Œ)")
    show = df[["id","region","domain","frame","sentiment"]].copy()
    show["keywords"] = df["keywords"].apply(lambda ks: ", ".join([w for w, _ in ks][:8]))
    st.dataframe(show.head(20), use_container_width=True)

    st.subheader("í”„ë ˆì„ ë¶„í¬")
    fr = df["frame"].fillna("Unknown").value_counts().reset_index()
    fr.columns = ["frame","count"]
    st.plotly_chart(px.bar(fr, x="frame", y="count", text="count"), use_container_width=True)

    # ì›Œë“œí´ë¼ìš°ë“œ(ì „ì²´)
    st.subheader("â˜ï¸ ì›Œë“œí´ë¼ìš°ë“œ")
    corpus = " ".join(df["norm"].dropna().tolist())
    if corpus.strip():
        wc = WordCloud(width=900, height=400, background_color="white").generate(corpus)
        fig, ax = plt.subplots(figsize=(10,4)); ax.imshow(wc); ax.axis("off"); st.pyplot(fig)
    else:
        st.warning("ìœ íš¨í•œ ë‹¨ì–´ê°€ ì—†ì–´ ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")

    save_jsonl(df, P(bundle, "analyze.jsonl"))
    st.success("analyze.jsonl ì €ì¥ ì™„ë£Œ")

# =========================
# Gate (ì²´í¬ë¦¬ìŠ¤íŠ¸ ë£° â†’ ì‹ í˜¸)
# =========================
CHECKLIST = {
    "Conflict":  {"êµì „":0.4, "ì „ìŸ":0.5, "ì‚¬ë§":0.6, "êµ°ì‚¬":0.3, "ë¯¸ì‚¬ì¼":0.5, "í›ˆë ¨":0.2},
    "Diplomacy": {"í˜‘ìƒ":0.4, "í•©ì˜":0.5, "íšŒë‹´":0.4, "ì¤‘ì¬":0.3, "ì œì¬":0.3},
    "Economic":  {"ìœ„ê¸°":0.5, "ë¬¼ê°€":0.3, "ê¸ˆë¦¬":0.3, "í™˜ìœ¨":0.3, "íŒŒì—…":0.4, "ê³µê¸‰ë§":0.4},
    "Domestic":  {"ì‹œìœ„":0.4, "ë²•ì•ˆ":0.2, "ê²€ì°°":0.2, "ë¶€íŒ¨":0.3, "íƒ„í•µ":0.5},
    "Disaster":  {"ì§€ì§„":0.6, "íƒœí’":0.5, "í­ìš°":0.4, "í™”ì¬":0.4, "ì „ì—¼ë³‘":0.5},
}
def match_signals(text: str, frame: str) -> float:
    w = CHECKLIST.get(frame, {})
    score = 0.0
    for k, val in w.items():
        if k in (text or ""):
            score += val
    return float(min(1.0, score))

def page_gate(bundle: str, threshold: float):
    st.header("ğŸšª Gate â€“ ì²´í¬ë¦¬ìŠ¤íŠ¸ ë§¤ì¹­")
    df = load_jsonl(P(bundle, "analyze.jsonl"))
    if df.empty:
        st.info("Analyze ê²°ê³¼ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        return

    df["signal"] = df.apply(lambda r: match_signals(r.get("norm",""), r.get("frame","Unknown")), axis=1)
    st.subheader("ì‹ í˜¸ê°’ ë¶„í¬")
    st.plotly_chart(px.histogram(df, x="signal", nbins=20), use_container_width=True)

    st.subheader("ì„ê³„ê°’ ì¡°ì •")
    th = st.slider("Gate ì„ê³„ê°’", 0.0, 1.0, float(threshold), 0.05, key="gate_th")
    df["gate_pass"] = df["signal"] >= th
    st.write(f"âœ… Gate í†µê³¼ ê¸°ì‚¬ ìˆ˜: {int(df['gate_pass'].sum())} / {len(df)}")

    save_jsonl(df, P(bundle, "gate.jsonl"))
    st.success("gate.jsonl ì €ì¥ ì™„ë£Œ")

# =========================
# Scoring (ê°€ì¤‘í•© + EWMA)
# =========================
def ewma(series: pd.Series, alpha=0.3):
    out = []
    s = None
    for v in series:
        s = v if s is None else (alpha*v + (1-alpha)*s)
        out.append(s)
    return out

def page_scoring(bundle: str):
    st.header("ğŸ“Š Scoring â€“ ìœ„í—˜ë„ ì ìˆ˜í™”")
    df = load_jsonl(P(bundle, "gate.jsonl"))
    if df.empty:
        st.info("Gate ê²°ê³¼ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        return

    # ìœ„í—˜ë„ = 0.5*signal + 0.3*neg(-sentiment) + 0.2*frame_weight
    frame_w = df["frame"].map({
        "Conflict":0.9,"Disaster":0.8,"Economic":0.6,"Domestic":0.5,"Diplomacy":0.4
    }).fillna(0.3)
    neg = (-pd.to_numeric(df["sentiment"], errors="coerce").fillna(0)).clip(lower=0)
    sig = pd.to_numeric(df["signal"], errors="coerce").fillna(0)
    risk = 0.5*sig + 0.3*neg + 0.2*frame_w
    df["risk_raw"] = risk.clip(0,1)

    # ë‚ ì§œ ì •ë ¬ í›„ EWMA
    dates = pd.to_datetime(df.get("date", datetime.utcnow().date()))
    df = df.assign(date=dates).sort_values("date")
    df["risk"] = ewma(df["risk_raw"], alpha=0.35)

    st.subheader("ìœ„í—˜ ì ìˆ˜ ì¶”ì´")
    st.plotly_chart(px.line(df, x="date", y="risk", markers=True), use_container_width=True)

    save_jsonl(df, P(bundle, "scoring.jsonl"))
    st.success("scoring.jsonl ì €ì¥ ì™„ë£Œ")

# =========================
# Fusion (ë³´ì •/ì‹ ë¢°ë„)
# =========================
def page_fusion(bundle: str):
    st.header("ğŸ”— Fusion â€“ ì ìˆ˜ ë³´ì •/í†µí•©")
    df = load_jsonl(P(bundle, "scoring.jsonl"))
    if df.empty:
        st.info("Scoring ê²°ê³¼ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        return

    # min-max ë³´ì • + ì‹ ë¢°ë„(í‚¤ì›Œë“œ ìˆ˜ + frame_hits í•©)
    mm = (pd.Series(df["risk"]) - pd.Series(df["risk"]).min()) / (pd.Series(df["risk"]).max() - pd.Series(df["risk"]).min() + 1e-9)
    df["risk_fused"] = mm.fillna(0)

    conf = df["keywords"].apply(lambda ks: len(ks) if isinstance(ks, list) else 0) + \
            df["frame_hits"].apply(lambda d: sum(d.values()) if isinstance(d, dict) else 0)
    df["confidence"] = (conf - conf.min()) / (conf.max() - conf.min() + 1e-9)

    st.subheader("Fusion ì „/í›„ ë¹„êµ")
    st.plotly_chart(px.scatter(df, x="risk", y="risk_fused", color="confidence"), use_container_width=True)

    save_jsonl(df, P(bundle, "fusion.jsonl"))
    st.success("fusion.jsonl ì €ì¥ ì™„ë£Œ")

# =========================
# Blocks (EDS): í”„ë ˆì„/ë„ë©”ì¸ ê¸°ë°˜ ë¸”ë¡
# =========================
def page_blocks(bundle: str):
    st.header("ğŸ§± Blocks (EDS)")
    df = load_jsonl(P(bundle, "fusion.jsonl"))
    if df.empty:
        st.info("Fusion ê²°ê³¼ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        return

    df["block"] = df.apply(lambda r: f"{r.get('frame','Unknown')}_{r.get('domain','Other')}", axis=1)

    st.subheader("ê¸°ì‚¬ â†” ë¸”ë¡ ë§¤í•‘ (ìƒ˜í”Œ)")
    st.dataframe(df[["id","region","domain","frame","block","risk_fused"]].head(30), use_container_width=True)

    save_jsonl(df, P(bundle, "blocks.jsonl"))
    st.success("blocks.jsonl ì €ì¥ ì™„ë£Œ")

# =========================
# Scenarios: ë¸”ë¡ ë¬¶ìŒ â†’ ì‹œë‚˜ë¦¬ì˜¤
# =========================
def page_scenarios(bundle: str):
    st.header("ğŸ“œ Scenarios â€“ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„±")
    df = load_jsonl(P(bundle, "blocks.jsonl"))
    if df.empty:
        st.info("Blocks ê²°ê³¼ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        return

    grp = df.groupby(["block","frame","domain","region"], dropna=False)["risk_fused"].mean().reset_index()
    grp["title"] = grp.apply(lambda r: f"{r['region']} - {r['frame']} ë¦¬ìŠ¤í¬", axis=1)
    grp["risk"]  = grp["risk_fused"].round(3)

    st.subheader("ì‹œë‚˜ë¦¬ì˜¤ ì¹´ë“œ (Top 8)")
    top = grp.sort_values("risk", ascending=False).head(8)
    for _, r in top.iterrows():
        st.markdown(
            f"<div style='padding:10px;border-radius:10px;background:#f6f8fb;margin:6px 0'>"
            f"<b>{r['title']}</b><br>ë„ë©”ì¸: {r['domain']} | ë¸”ë¡: {r['block']}<br>"
            f"<b>Risk:</b> {r['risk']}</div>", unsafe_allow_html=True
        )

    save_jsonl(grp, P(bundle, "scenarios.jsonl"))
    st.success("scenarios.jsonl ì €ì¥ ì™„ë£Œ")

# =========================
# Alerts: ì‹œë‚˜ë¦¬ì˜¤ ìœ„í—˜ë„ â†’ ê²½ë³´
# =========================
def page_alerts(bundle: str, alert_threshold: float):
    st.header("ğŸš¨ Alerts â€“ ê²½ë³´ ìƒì„±")
    scen = load_jsonl(P(bundle, "scenarios.jsonl"))
    if scen.empty:
        st.info("Scenarios ê²°ê³¼ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        return

    th = st.slider("ê²½ë³´ ê¸°ì¤€ ì ìˆ˜", 0.0, 1.0, float(alert_threshold), 0.05, key="alert_th")
    alerts = scen.copy()
    alerts["is_alert"] = alerts["risk"] >= th
    st.write(f"ë°œìƒ ê²½ë³´ ìˆ˜: {int(alerts['is_alert'].sum())}")

    st.subheader("ì§€ì—­/ë¶„ì•¼ ë¶„í¬")
    if "region" in alerts:
        st.plotly_chart(px.bar(alerts["region"].value_counts().reset_index().rename(columns={"index":"region","region":"count"}), x="region", y="count"), use_container_width=True)
    if "domain" in alerts:
        st.plotly_chart(px.pie(alerts, names="domain", title="ë„ë©”ì¸ ë¶„í¬"), use_container_width=True)

    save_jsonl(alerts, P(bundle, "alerts.jsonl"))
    st.success("alerts.jsonl ì €ì¥ ì™„ë£Œ")

# =========================
# Event Blocks: í”„ë ˆì„Ã—ì¼ì ê·¸ë£¹
# =========================
def page_event_blocks(bundle: str):
    st.header("ğŸ“¦ Event Blocks â€“ ê°„ì´ í´ëŸ¬ìŠ¤í„°")
    df = load_jsonl(P(bundle, "alerts.jsonl"))
    if df.empty:
        st.info("Alerts ê²°ê³¼ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        return

    # ì¼ì ìƒì„±
    if "date" not in df.columns:
        df["date"] = datetime.utcnow().date().isoformat()
    df["date"] = pd.to_datetime(df["date"], errors="coerce").dt.date

    df["cluster"] = df["frame"].astype(str) + "_" + pd.Series(df["date"]).astype(str)
    agg = df.groupby("cluster")["risk"].mean().reset_index().rename(columns={"risk":"risk_mean"})
    st.dataframe(agg.head(30), use_container_width=True)

    # íˆíŠ¸ë§µ ëŠë‚Œ(ë§‰ëŒ€)
    st.plotly_chart(px.bar(agg, x="cluster", y="risk_mean"), use_container_width=True)

    save_jsonl(agg, P(bundle, "event_blocks.jsonl"))
    st.success("event_blocks.jsonl ì €ì¥ ì™„ë£Œ")

# =========================
# Ledger: ë¡œê·¸ í…Œì´ë¸”
# =========================
def page_ledger(bundle: str):
    st.header("ğŸ“’ Ledger")
    files = [
        "ingest.jsonl","normalize.jsonl","analyze.jsonl","gate.jsonl","scoring.jsonl",
        "fusion.jsonl","blocks.jsonl","scenarios.jsonl","alerts.jsonl","event_blocks.jsonl"
    ]
    rows = []
    for f in files:
        p = P(bundle, f)
        rows.append({"file": f, "exists": os.path.exists(p), "size": (os.path.getsize(p) if os.path.exists(p) else 0)})
    st.dataframe(pd.DataFrame(rows), use_container_width=True)

# =========================
# ì „ì²´ íŒŒì´í”„ë¼ì¸(Run All)
# =========================
def run_all(bundle: str, gate_th: float, alert_th: float):
    # ì „ ë‹¨ê³„ ì—°ì† ì‹¤í–‰ (ë°ì´í„°ê°€ ì—†ìœ¼ë©´ í•´ë‹¹ ë‹¨ê³„ ê±´ë„ˆë›°ì§€ ì•Šê³  ë¹ˆ ì²˜ë¦¬)
    if load_jsonl(P(bundle, "ingest.jsonl")).empty:
        st.info("Run Allì„ ìœ„í•´ ìµœì†Œ 1ê°œ ê¸°ì‚¬ë¥¼ Ingestì— ì €ì¥í•˜ì„¸ìš”.")
        return
    page_normalize(bundle)
    page_analyze(bundle)
    page_gate(bundle, gate_th)
    page_scoring(bundle)
    page_fusion(bundle)
    page_blocks(bundle)
    page_scenarios(bundle)
    page_alerts(bundle, alert_th)
    page_event_blocks(bundle)
    page_ledger(bundle)
    st.success("ğŸ‰ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ")

# =========================
# Main
# =========================
def main():
    st.set_page_config(page_title="NWW Early Warning Dashboard", layout="wide", initial_sidebar_state="expanded")

    st.sidebar.header("âš™ï¸ ì„¤ì •")
    bundle = st.sidebar.text_input("Bundle ID (data/<bundle>)", "sample")
    gate_th = st.sidebar.slider("Gate ì„ê³„ê°’", 0.0, 1.0, 0.5, 0.05)
    alert_th = st.sidebar.slider("Alert ì„ê³„ê°’", 0.0, 1.0, 0.7, 0.05)

    if st.sidebar.button("â–¶ Run All"):
        run_all(bundle, gate_th, alert_th)
        return  # í•œ ë²ˆì— ê·¸ë ¤ì¤Œ

    st.sidebar.markdown("---")
    page = st.sidebar.radio("ğŸ“Œ ë‹¨ê³„", [
        "Landing","Ingest","Normalize","Analyze","Gate","Scoring","Fusion",
        "Blocks (EDS)","Scenarios","Alerts","Event Blocks","Ledger"
    ])

    if page == "Landing":         page_overview(bundle)
    elif page == "Ingest":        page_ingest(bundle)
    elif page == "Normalize":     page_normalize(bundle)
    elif page == "Analyze":       page_analyze(bundle)
    elif page == "Gate":          page_gate(bundle, gate_th)
    elif page == "Scoring":       page_scoring(bundle)
    elif page == "Fusion":        page_fusion(bundle)
    elif page == "Blocks (EDS)":  page_blocks(bundle)
    elif page == "Scenarios":     page_scenarios(bundle)
    elif page == "Alerts":        page_alerts(bundle, alert_th)
    elif page == "Event Blocks":  page_event_blocks(bundle)
    elif page == "Ledger":        page_ledger(bundle)

if __name__ == "__main__":
    main()
