import os
import logging
from nwwpkg.ingest.extract import Extractor
from nwwpkg.preprocess.normalize import Normalizer
from nwwpkg.analyze.tag import Tagger

logger = logging.getLogger(__name__)

def run_pipeline(stage: str, bundle_dir: str) -> str:
    """
    Dispatcher: stage ê°’ì— ë”°ë¼ í•´ë‹¹ ë‹¨ê³„ ì‹¤í–‰
    ë°˜í™˜: ìƒì„±ëœ JSONL íŒŒì¼ ê²½ë¡œ
    """
    os.makedirs(bundle_dir, exist_ok=True)

    if stage == "ingest":
        logger.info("ğŸ“¥ Ingest ì‹¤í–‰")
        extractor = Extractor(bundle_dir)
        out_file = os.path.join(bundle_dir, "articles.jsonl")
        extractor.run(out_file)
        return out_file

    elif stage == "preprocess":
        logger.info("ğŸ§¹ Preprocess ì‹¤í–‰")
        normalizer = Normalizer()
        in_file = os.path.join(bundle_dir, "articles.jsonl")
        out_file = os.path.join(bundle_dir, "articles.norm.jsonl")
        log_file = os.path.join(bundle_dir, "logs", "normalize.log")
        os.makedirs(os.path.dirname(log_file), exist_ok=True)
        normalizer.run(in_file, out_file, log_file)
        return out_file

    elif stage == "analysis":
        logger.info("ğŸ” Analysis ì‹¤í–‰")
        tagger = Tagger()
        in_file = os.path.join(bundle_dir, "articles.norm.jsonl")
        out_file = os.path.join(bundle_dir, "kyw_sum.jsonl")
        tagger.run(in_file, out_file)
        return out_file

    elif stage == "scoring":
        logger.info("âš–ï¸ Scoring ì‹¤í–‰ (stub)")
        out_file = os.path.join(bundle_dir, "scores.jsonl")
        # TODO: ì‹¤ì œ scoring ëª¨ë“ˆ ì—°ê²°
        with open(out_file, "w", encoding="utf-8") as f:
            f.write("")
        return out_file

    elif stage == "scenarios":
        logger.info("ğŸ“‘ Scenario ìƒì„± ì‹¤í–‰ (stub)")
        out_file = os.path.join(bundle_dir, "scenarios.jsonl")
        # TODO: ì‹¤ì œ scenario ëª¨ë“ˆ ì—°ê²°
        with open(out_file, "w", encoding="utf-8") as f:
            f.write("")
        return out_file

    elif stage == "alerts":
        logger.info("ğŸš¨ Alerts ìƒì„± ì‹¤í–‰ (stub)")
        out_file = os.path.join(bundle_dir, "alerts.jsonl")
        # TODO: ì‹¤ì œ alerts ëª¨ë“ˆ ì—°ê²°
        with open(out_file, "w", encoding="utf-8") as f:
            f.write("")
        return out_file

    elif stage == "eds":
        logger.info("ğŸ“š EDS ì‹¤í–‰ (stub)")
        out_file = os.path.join(bundle_dir, "eds.jsonl")
        # TODO: ì‹¤ì œ EDS ëª¨ë“ˆ ì—°ê²°
        with open(out_file, "w", encoding="utf-8") as f:
            f.write("")
        return out_file

    else:
        raise ValueError(f"ì•Œ ìˆ˜ ì—†ëŠ” ë‹¨ê³„: {stage}")


def run_full_pipeline(bundle_id: str, base_dir: str = "data/bundles") -> str:
    """
    ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (Ingest â†’ Preprocess â†’ Analysis â†’ Scoring â†’ Scenarios â†’ Alerts â†’ EDS)
    """
    bundle_dir = os.path.join(base_dir, bundle_id)
    stages = ["ingest", "preprocess", "analysis", "scoring", "scenarios", "alerts", "eds"]

    last_out = None
    for stage in stages:
        try:
            logger.info(f"â–¶ï¸ {stage} ì‹¤í–‰")
            last_out = run_pipeline(stage, bundle_dir)
        except Exception as e:
            logger.error(f"âŒ {stage} ì‹¤íŒ¨: {e}")
            break
    return last_out
